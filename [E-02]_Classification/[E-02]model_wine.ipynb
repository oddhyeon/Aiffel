{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-cooper",
   "metadata": {},
   "source": [
    "# EXPLORATION 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-verification",
   "metadata": {},
   "source": [
    "## 3. 와인 클래스 예측\n",
    "\n",
    "\n",
    "### 1. Imort module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artificial-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine # 데이터 불러오기\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score # 정확도 확인\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.tree import DecisionTreeClassifier # DecisionTree 모델 정의\n",
    "from sklearn.linear_model import SGDClassifier # SGDClassifier 모델 정의\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression 모델 정의\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest 모델 정의\n",
    "from sklearn import svm # SVM 모델 정의\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import numpy as np # numpy 정의\n",
    "import pandas as pd # 데이터프레임을 위한 판다스 정의\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-committee",
   "metadata": {},
   "source": [
    "### 2. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exceptional-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_target = wine.target\n",
    "bcdf = pd.DataFrame(data=wine_data, columns=wine.feature_names) # 판다스 DataFrame 자료형 변환\n",
    "# pd.set_option('display.max_columns', None) # 데이터 프레임 생략없이 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-digit",
   "metadata": {},
   "source": [
    "### 3.Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immediate-mineral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 :  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "총 데이터 및 특징 갯수 :  (178, 13)\n",
      "Lable :  ['class_0' 'class_1' 'class_2'] \n",
      "\n",
      "특징 이름 :  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print('분류 : ',wine.keys()) # 키\n",
    "print('총 데이터 및 특징 갯수 : ',wine_data.shape) \n",
    "print('Lable : ',wine.target_names,'\\n')  # 타겟(정답)에 이름\n",
    "print('특징 이름 : ',wine.feature_names,'\\n') # 각 특징에 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-peripheral",
   "metadata": {},
   "source": [
    "- 와인 데이터는 178개로 각각 13개의 특성을 나타내고 있습니다.\n",
    "- Lable 데이터에 경우 클래스 별로 구분되고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-phoenix",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcdf.columns\n",
    "bcdf.head()       # 데이터 프레임 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protecting-point",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
       "count       178.000000  178.000000                    178.000000   178.000000  \n",
       "mean          5.058090    0.957449                      2.611685   746.893258  \n",
       "std           2.318286    0.228572                      0.709990   314.907474  \n",
       "min           1.280000    0.480000                      1.270000   278.000000  \n",
       "25%           3.220000    0.782500                      1.937500   500.500000  \n",
       "50%           4.690000    0.965000                      2.780000   673.500000  \n",
       "75%           6.200000    1.120000                      3.170000   985.000000  \n",
       "max          13.000000    1.710000                      4.000000  1680.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcdf.describe()   # 데이터 프레임으로 위 코드에 대한 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 설명 :  .. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('데이터 설명 : ',wine.DESCR,'\\n') # 데이터에 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-qualification",
   "metadata": {},
   "source": [
    "### 4. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hindu-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X_train: 142 number of X_test: 36\n",
      "(142, 13) (142,)\n",
      "(36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "x_train,x_test,y_train,y_test = train_test_split(wine_data,\n",
    "                                                 wine_target,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=13)\n",
    "print('number of X_train:', len(x_train), 'number of X_test:', len(x_test))\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-israel",
   "metadata": {},
   "source": [
    "- 테스트,훈련 데이터 분할 및 분할 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-columbus",
   "metadata": {},
   "source": [
    "### 5. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indirect-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "decision_tree = DecisionTreeClassifier(random_state=16)\n",
    "sgd_model = SGDClassifier(random_state=16)\n",
    "logistic_model = LogisticRegression(random_state=16,solver='liblinear',max_iter=30000)\n",
    "random_forest = RandomForestClassifier(random_state=16)\n",
    "svm_model = svm.SVC(random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-ghana",
   "metadata": {},
   "source": [
    "- 각 시드를 16으로 조정하여 결과값 고정\n",
    "- solver : 최적화 문제에 사용하는 알고리즘 max_iter : 계산에 사용할 작업 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-bulletin",
   "metadata": {},
   "source": [
    "### 6. 각 모델별 훈련 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "asian-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Tree Classifier]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       0.93      0.87      0.90        15\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "\n",
      "\n",
      "[SGD Classifier]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79        12\n",
      "           1       0.65      0.87      0.74        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.45      0.59      0.51        36\n",
      "weighted avg       0.50      0.67      0.57        36\n",
      "\n",
      "\n",
      "\n",
      "[Logistic Regression Classifier]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.96      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "[Random Forest Classifier]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "[SVM Classifier]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.73      0.73      0.73        15\n",
      "           2       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.76      0.76      0.76        36\n",
      "weighted avg       0.78      0.78      0.78        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "wine_accuracy = {}\n",
    "\n",
    "# \n",
    "decision_tree.fit(x_train,y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "print('[Decision Tree Classifier]\\n\\n',classification_report(y_test,y_pred))\n",
    "wine_accuracy['Decision Tree Classifier'] = accuracy_score(y_test,y_pred)\n",
    "\n",
    "sgd_model.fit(x_train,y_train)\n",
    "y_pred = sgd_model.predict(x_test)\n",
    "print('\\n\\n[SGD Classifier]\\n\\n',classification_report(y_test,y_pred))\n",
    "wine_accuracy['SGD Classifier'] = accuracy_score(y_test,y_pred)\n",
    "\n",
    "logistic_model.fit(x_train,y_train)\n",
    "y_pred = logistic_model.predict(x_test)\n",
    "print('\\n\\n[Logistic Regression Classifier]\\n\\n',classification_report(y_test,y_pred,labels=np.unique(y_pred))) # ,한 번 예측 될  경우 관심없음\n",
    "wine_accuracy['Logistic Regression Classifier'] = accuracy_score(y_test,y_pred)\n",
    "\n",
    "random_forest.fit(x_train,y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "print('\\n\\n[Random Forest Classifier]\\n\\n',classification_report(y_test,y_pred))\n",
    "wine_accuracy['Random Forest Classifier'] = accuracy_score(y_test,y_pred)\n",
    "\n",
    "svm_model.fit(x_train,y_train)\n",
    "y_pred = svm_model.predict(x_test)\n",
    "print('\\n\\n[SVM Classifier]\\n\\n',classification_report(y_test,y_pred))\n",
    "wine_accuracy['SVM Classifier'] = accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eligible-administrator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier : 0.9166666666666666\n",
      "SGD Classifier       : 0.6666666666666666\n",
      "Logistic Regression Classifier : 0.9722222222222222\n",
      "Random Forest Classifier : 1.0\n",
      "SVM Classifier       : 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "for i in wine_accuracy.items():\n",
    "    print(f\"{i[0]:<20} : {i[1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-machinery",
   "metadata": {},
   "source": [
    "- 단순히 정확도를 기준으로 보면 Random Forest Classifier 모델이 가장 높게 나왔다.\n",
    "- 하지만 더 다양한 측정 기준을 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wrapped-possibility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f944542ce90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(random_forest, x_test, y_test, values_format='d',display_labels=wine.target_names,cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-scroll",
   "metadata": {},
   "source": [
    "- Confusion matrix를 시각화 한 결과이다\n",
    "    \n",
    "    클래스 0~2까지 예측한 결과값으로 현재 데이터로 봤을때 class_1이 가장 높게 측정된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-gross",
   "metadata": {},
   "source": [
    "## 7.프로젝트 정리\n",
    "\n",
    "     와인 클래스 예측에 경우 라벨을 맞추는 과정이 중요한 것 같다. 손글씨와 같이 가장 중간값이 높게 측정되었다\n",
    "    \n",
    "     정확도면에서 다른 모델보다 우수했던 Random_Forest의 경우 정확도 말고도 다른 결과도 타 모델에 비해 우수한 성적이 나왔음으로\n",
    "     와인 클래스 예측은 Random_Forest 모델을 5개의 모델중 추천한다.\n",
    "     \n",
    "     시각화와 전처리,성능평가에 관해 보다 많은것을 배울 수 있었고 많은것을 생각할 수 있게 만들던 파트였다. scikit-learn 데이터 덕분에\n",
    "     좀 더 수월하게 모델들을 학습할 수 있었던 계기가 되었던것같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
