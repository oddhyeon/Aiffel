{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoingDeeper1. Resnet_AblationStudy\n",
    "=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목표\n",
    "___________________________________________________________________________________________________________________\n",
    "- 논문을 활용하여 ResNet 구현하기\n",
    "- Plain모델과 ResNet모델 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet(Deep Residual Learning for Image Recognition) for Keras\n",
    "\n",
    "    \n",
    "![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQP9is%2FbtqTcQ4s52b%2FARS9MrzwdbhJKRKDhtkWx1%2Fimg.png)\n",
    "\n",
    "- Resnet은 기존에 딥러닝에 어려운 개념보다는 방법론적으로 새로운 개념인 잔차(Residual)라는 개념이 적용되었다.\n",
    "- Residual(잔차)란 쉽게 말해서 결과의 오류 정도로 생각하면 되는데  __Y에서 X를 뺀 나머지__  라고 생각하면 된다.\n",
    "- 지금까지는 평가는 residaul이 평가 기준으로만 사용되어왔는데 Resnet 이후로 많은 논문에 인용되게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Abstract\n",
    "    초록 에서는 depth의 중요성과 desidual learning에 대해 간략히 설명하고 있다.\n",
    "    역대 대회에서는 dept의 깊이가 모델의 성능에 큰 영향을 준다는 것을 알 수 있다. \n",
    "    즉, visual recognition task에서 depth는 매우 중요한 요소이다. 하지만 depth가 올라감에 따라  \n",
    "    오버 피팅, Gradient 소멸, 연산량 증가 등의 문제도 같이 따라오는데 residual learning이 문제를 해결해 주었다.\n",
    "    \n",
    "    여기서의 residual learning이란 이전 layer의 결과를 다시 이용하여 합치는것이라 보면된다.\n",
    "    즉, 입력 layer를 다시 이용하는 residual funcion을 사용하여 더 쉬운 최적화와 깊은 네트워크에서의 정확도 향상이 가능했다고 한다.\n",
    "    결과적으로 ResNet이 VGGNet의 8배인 152 layer를 사용하였으며, 앙상블 기법을 적용해 오차를 3.75% 까지 낮출 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인해 봅니다.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "dataset_name = 'cats_vs_dogs'\n",
    "ds_train, ds_info_train = tfds.load('cats_vs_dogs',split='train[:80%]',as_supervised=True,  with_info=True)\n",
    "ds_valid, ds_info_valid = tfds.load('cats_vs_dogs',split='train[80%:]',as_supervised=True,  with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "    'image/filename': Text(shape=(), dtype=tf.string),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_info_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds,is_test=False,batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,\n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 블록화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1(x):\n",
    "    \n",
    "    x = keras.layers.Conv2D(64,(7,7),strides=(2,2),padding='same',name='conv2d7x7')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3),strides=2,name='maxpooling')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_short(x,filters,stage_num,block_num):\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=(2,2),\n",
    "     name = f'stage{stage_num}_{block_num+1}_short')(x)\n",
    "    x = keras.layers.BatchNormalization()(x) \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_short50(x,filters, stage_num, block_num):\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters=filters,kernel_size=(1,1),padding='same', strides=(1,1), \n",
    "        name=f'stage{stage_num}_{block_num+1}_short')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2x(x,first_layer,block_num,kernel_size,\n",
    "    filters,stage_num,num_layer=34,is_plain=False):\n",
    "    \"\"\"\n",
    "    conv2\n",
    "    1) layer-18: [[3*3],64, [3*3],64]*2\n",
    "    2) layer-34: [[3*3],64, [3*3],64]*3\n",
    "    3) layer-50: [[1*1],64, [3*3],64, [1*1],256]\n",
    "    \"\"\"\n",
    "    \n",
    "    # shortcut 정의\n",
    "    shortcut = x\n",
    "    \n",
    "    if num_layer == 18 or num_layer == 34: # layer가 18,34에 경우 conv2D 레이어\n",
    "        # Conv2D\n",
    "        x = keras.layers.Conv2D(filters=filters,kernel_size=kernel_size,\n",
    "            padding='same', name=f'stage{stage_num}_{block_num+1}_conv1'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn1')(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=filters,kernel_size=kernel_size,\n",
    "            padding='same', name=f'stage{stage_num}_{block_num+1}_conv2')(x)\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn2')(x)\n",
    "\n",
    "        if not is_plain:\n",
    "            x = tf.keras.layers.Add(name=f'stage{stage_num}_{block_num+1}_add')([x, shortcut])\n",
    "\n",
    "        # activation\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        \n",
    "    else:\n",
    "        # 3개 층 중에서 첫번째 층만 shortcut이고 나머지 두 개는 입력값을 그대로 사용\n",
    "        \n",
    "        \n",
    "        x = keras.layers.Conv2D(filters=filters,kernel_size=kernel_size[0],\n",
    "            padding='same', name=f'stage{stage_num}_{block_num+1}_conv1')(x)\n",
    "        \n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn1')(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D( filters=filters,kernel_size=kernel_size[1],\n",
    "        padding='same',name=f'stage{stage_num}_{block_num+1}_conv2')(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn2')(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "        # 마지막 레이어는 4배이다.\n",
    "        x = keras.layers.Conv2D(filters=filters*4, kernel_size=kernel_size[2],\n",
    "        name=f'stage{stage_num}_{block_num+1}_conv3', padding='same' )(x)\n",
    "        \n",
    "        # short\n",
    "        conv3_short = conv_short50(shortcut, filters=filters*4, stage_num=stage_num, block_num=block_num)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn3')(x)\n",
    "        \n",
    "        if not is_plain:\n",
    "            if first_layer:\n",
    "                # add\n",
    "                x = tf.keras.layers.Add(name=f'stage{stage_num}_{block_num+1}_add')([x, conv3_short])\n",
    "            else:\n",
    "                # add\n",
    "                x = tf.keras.layers.Add(name=f'stage{stage_num}_{block_num+1}_add')([x, shortcut])\n",
    "            \n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3_5_x(x,\n",
    "                 block_num,\n",
    "                 kernel_size,\n",
    "                 filters,\n",
    "                 first_layer, # True/False,\n",
    "                 stage_num,\n",
    "                 num_layer=34,\n",
    "                 is_plain=False\n",
    "                 ):\n",
    "    \n",
    "    shortcut = x\n",
    "    \n",
    "    # kernel_size_copy\n",
    "    if num_layer == 50 or num_layer == 101 or num_layer == 152:\n",
    "        kernel_size_copy = kernel_size.copy()\n",
    "        kernel_size = kernel_size_copy[0]\n",
    "        \n",
    "    # <!-- first block --!>    \n",
    "    # 첫 번재 층은 stride를 해야 함.\n",
    "    if first_layer:\n",
    "        \n",
    "        # Conv2D\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same', strides=(2,2), # stride\n",
    "            name=f'stage{stage_num}_{block_num+1}_conv1'\n",
    "        )(x)\n",
    "    \n",
    "    else:\n",
    "        # Conv2D\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "            name=f'stage{stage_num}_{block_num+1}_conv1'\n",
    "        )(x)\n",
    "     \n",
    "    x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn1')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    if num_layer==50 or num_layer==101 or num_layer==152: \n",
    "        # <!-- second block --!>\n",
    "        kernel_size = kernel_size_copy[1]\n",
    "#         print(f'stage{stage_num}_{block_num+1}_conv2')\n",
    "#         print('kernel_size: ', kernel_size)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            name=f'stage{stage_num}_{block_num+1}_conv2',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn2')(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    # <!-- third block --!>\n",
    "#     print(f'stage{stage_num}_{block_num+1}_conv2')\n",
    "#     print('kernel_size: ', kernel_size)\n",
    "    conv_num=3\n",
    "    if num_layer==50 or num_layer==101 or num_layer==152:\n",
    "        filters=filters*4\n",
    "        kernel_size = kernel_size_copy[2]\n",
    "    else: conv_num-=1\n",
    "    \n",
    "    \n",
    "    # Conv2D\n",
    "    x = keras.layers.Conv2D(filters=filters,kernel_size=kernel_size,\n",
    "        name=f'stage{stage_num}_{block_num+1}_conv{conv_num}',padding='same')(x)\n",
    "\n",
    "    conv3_short = conv_short(shortcut, filters, stage_num=stage_num, block_num=block_num)\n",
    "    conv3_short50 = conv_short50(shortcut, filters, stage_num=stage_num, block_num=block_num)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'stage{stage_num}_{block_num+1}_bn{conv_num}')(x)\n",
    "    \n",
    "    if not is_plain:\n",
    "        if first_layer:\n",
    "            # add\n",
    "            x = tf.keras.layers.Add(name=f'stage{stage_num}_{block_num+1}_add')([x, conv3_short])\n",
    "        else:\n",
    "            # add\n",
    "            x = tf.keras.layers.Add(name=f'stage{stage_num}_{block_num+1}_add')([x, shortcut])\n",
    "\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_resnet(input_layer, num_layer=34, is_residual=True, is_plain=False):\n",
    "    \n",
    "    # layer개수에 따른 cnn층 개수\n",
    "    cnn_layer ={\n",
    "                18 : [2,2,2,2], \n",
    "                34 : [3,4,6,3], \n",
    "                50 : [3,4,6,3], \n",
    "                101 : [3,4,23,3],\n",
    "                152 : [3,8,36,3]\n",
    "                }\n",
    "    \n",
    "    # layer개수에 따른 filter 리스트\n",
    "    filter_list = [64, 128, 256, 512]\n",
    "    \n",
    "    # layer별 커널 사이즈\n",
    "    kernel_size_dict = {18:(3,3),\n",
    "                   34:(3,3),\n",
    "                   50:[(1,1),(3,3),(1,1)],\n",
    "                   101:[(1,1),(3,3),(1,1)],\n",
    "                   152:[(1,1),(3,3),(1,1)]}\n",
    "    \n",
    "    # layer별 커널 사이즈\n",
    "    kernel_size = kernel_size_dict[num_layer]\n",
    "    \n",
    "    # cnn층 블록 개수 리스트(num_cnn_list) 할당\n",
    "    num_cnn_list = cnn_layer[num_layer]\n",
    "    \n",
    "    # 전체 conv 블록 개수\n",
    "    num_conv = len(num_cnn_list)\n",
    "    \n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    \n",
    "    # 7*7, 64, stride2 + maxpooling\n",
    "    x = conv1(x)\n",
    "    \n",
    "    # stage num 정의\n",
    "    stage_num = 2\n",
    "    \n",
    "    # conv_idx 정의\n",
    "    conv_idx=0\n",
    "\n",
    "    # conv2_x\n",
    "    \n",
    "    # layer-50,101,152만 해당\n",
    "    first_layer = [True,False,False]\n",
    "    \n",
    "    for i in range(num_cnn_list[conv_idx]):\n",
    "        x = conv_2x(x,\n",
    "                         first_layer=first_layer[i],\n",
    "                         block_num=i,\n",
    "                         kernel_size=kernel_size,\n",
    "                         filters=filter_list[conv_idx],\n",
    "                         stage_num=stage_num,\n",
    "                         num_layer=num_layer,\n",
    "                         is_plain=is_plain\n",
    "                         )\n",
    "#     print('conv2 완료')\n",
    "\n",
    "    # conv3_x\n",
    "    stage_num+=1\n",
    "    conv_idx+=1\n",
    "    if is_residual: # residual 있을때\n",
    "        first_layer = [True]\n",
    "        for _ in range(num_cnn_list[conv_idx]-1): first_layer.extend([False])\n",
    "    else:          # residual 없을때\n",
    "        first_layer = [False]*num_cnn_list[conv_idx]\n",
    "    \n",
    "    for i in range(num_cnn_list[conv_idx]):\n",
    "        x = conv3_5_x(x,\n",
    "                        block_num=i,\n",
    "                        kernel_size=kernel_size,\n",
    "                        filters=filter_list[conv_idx],\n",
    "                        first_layer=first_layer[i],\n",
    "                        stage_num=stage_num,\n",
    "                        num_layer=num_layer,\n",
    "                        is_plain=is_plain)\n",
    "        \n",
    "#     print('conv3 완료')\n",
    "\n",
    "    # conv4_x\n",
    "    stage_num+=1\n",
    "    conv_idx+=1\n",
    "    \n",
    "    if is_residual:\n",
    "        first_layer = [True]\n",
    "        for _ in range(num_cnn_list[conv_idx]-1): first_layer.extend([False])\n",
    "    else:\n",
    "        first_layer = [False]*num_cnn_list[conv_idx]\n",
    "#     print('first_layer: ',first_layer)\n",
    "    for i in range(num_cnn_list[conv_idx]):\n",
    "        x = conv3_5_x(x,\n",
    "                        block_num=i,\n",
    "                        kernel_size=kernel_size,\n",
    "                        filters=filter_list[conv_idx],\n",
    "                        first_layer=first_layer[i],\n",
    "                        stage_num=stage_num,\n",
    "                        num_layer=num_layer,\n",
    "                        is_plain=is_plain)\n",
    "#     print('conv4 완료')\n",
    "    # conv5_x\n",
    "    stage_num+=1\n",
    "    conv_idx+=1\n",
    "    \n",
    "    if is_residual:\n",
    "        first_layer = [True]\n",
    "        for _ in range(num_cnn_list[conv_idx]-1): first_layer.extend([False])\n",
    "    else:\n",
    "        first_layer = [False]*num_cnn_list[conv_idx]\n",
    "    \n",
    "    for i in range(num_cnn_list[conv_idx]):\n",
    "        x = conv3_5_x(x,\n",
    "                        block_num=i,\n",
    "                        kernel_size=kernel_size,\n",
    "                        filters=filter_list[conv_idx],\n",
    "                        first_layer=first_layer[i],\n",
    "                        stage_num=stage_num,\n",
    "                        num_layer=num_layer,\n",
    "                        is_plain=is_plain)\n",
    "#     print('conv5 완료')\n",
    "\n",
    "\n",
    "    x= keras.layers.AveragePooling2D(\n",
    "        pool_size=(2, 2), strides=2, padding='SAME', name='avg_pool')(x)\n",
    "    x = keras.layers.Flatten(name='flatten_11')(x)\n",
    "    # FC layer(2) --- 우리가 사용할 데이터는 '고양이', '개' 두 가지 클래스만 있으므로 이걸 사용해야함.\n",
    "    x = keras.layers.Dense(2,name='fc2')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d7x7 (Conv2D)              (None, 16, 16, 64)   9472        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d7x7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "maxpooling (MaxPooling2D)       (None, 7, 7, 64)     0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)         (None, 7, 7, 64)     36928       maxpooling[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 64)     0           stage2_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)         (None, 7, 7, 64)     36928       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_add (Add)              (None, 7, 7, 64)     0           stage2_1_bn2[0][0]               \n",
      "                                                                 maxpooling[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 64)     0           stage2_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)         (None, 7, 7, 64)     36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn1 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 64)     0           stage2_2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)         (None, 7, 7, 64)     36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn2 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_add (Add)              (None, 7, 7, 64)     0           stage2_2_bn2[0][0]               \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 64)     0           stage2_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)         (None, 7, 7, 64)     36928       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn1 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 64)     0           stage2_3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)         (None, 7, 7, 64)     36928       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn2 (BatchNormalizatio (None, 7, 7, 64)     256         stage2_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_add (Add)              (None, 7, 7, 64)     0           stage2_3_bn2[0][0]               \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 64)     0           stage2_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv1 (Conv2D)         (None, 4, 4, 128)    73856       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 128)    0           stage3_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_short (Conv2D)         (None, 4, 4, 128)    8320        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 128)    512         stage3_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_add (Add)              (None, 4, 4, 128)    0           stage3_1_bn2[0][0]               \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 128)    0           stage3_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 128)    0           stage3_2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_add (Add)              (None, 4, 4, 128)    0           stage3_2_bn2[0][0]               \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 128)    0           stage3_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 128)    0           stage3_3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_add (Add)              (None, 4, 4, 128)    0           stage3_3_bn2[0][0]               \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 128)    0           stage3_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 128)    0           stage3_4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_add (Add)              (None, 4, 4, 128)    0           stage3_4_bn2[0][0]               \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 128)    0           stage3_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv1 (Conv2D)         (None, 2, 2, 256)    295168      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 2, 2, 256)    0           stage4_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_short (Conv2D)         (None, 2, 2, 256)    33024       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 2, 2, 256)    1024        stage4_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_add (Add)              (None, 2, 2, 256)    0           stage4_1_bn2[0][0]               \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 2, 2, 256)    0           stage4_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 2, 2, 256)    0           stage4_2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_add (Add)              (None, 2, 2, 256)    0           stage4_2_bn2[0][0]               \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 2, 2, 256)    0           stage4_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 2, 2, 256)    0           stage4_3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_add (Add)              (None, 2, 2, 256)    0           stage4_3_bn2[0][0]               \n",
      "                                                                 activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 2, 2, 256)    0           stage4_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 2, 2, 256)    0           stage4_4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_add (Add)              (None, 2, 2, 256)    0           stage4_4_bn2[0][0]               \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 2, 2, 256)    0           stage4_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 2, 2, 256)    0           stage4_5_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_add (Add)              (None, 2, 2, 256)    0           stage4_5_bn2[0][0]               \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 2, 2, 256)    0           stage4_5_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_6_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 2, 2, 256)    0           stage4_6_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_6_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_add (Add)              (None, 2, 2, 256)    0           stage4_6_bn2[0][0]               \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 2, 2, 256)    0           stage4_6_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv1 (Conv2D)         (None, 1, 1, 512)    1180160     activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn1 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 1, 1, 512)    0           stage5_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_short (Conv2D)         (None, 1, 1, 512)    131584      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn2 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1, 1, 512)    2048        stage5_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_add (Add)              (None, 1, 1, 512)    0           stage5_1_bn2[0][0]               \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 1, 1, 512)    0           stage5_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv1 (Conv2D)         (None, 1, 1, 512)    2359808     activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn1 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 1, 1, 512)    0           stage5_2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn2 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_add (Add)              (None, 1, 1, 512)    0           stage5_2_bn2[0][0]               \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 1, 1, 512)    0           stage5_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv1 (Conv2D)         (None, 1, 1, 512)    2359808     activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn1 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 1, 1, 512)    0           stage5_3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn2 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_add (Add)              (None, 1, 1, 512)    0           stage5_3_bn2[0][0]               \n",
      "                                                                 activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 1, 1, 512)    0           stage5_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 512)    0           activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 2)            1026        flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,311,234\n",
      "Trainable params: 21,294,210\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet34_input_layer_ex = keras.layers.Input(shape=(32,32,3), name='input_layer')   # 입력 레이어 생성\n",
    "resnet34_block_output_ex = build_resnet(resnet34_input_layer_ex)\n",
    "\n",
    "resnet34_ex = keras.Model(inputs=resnet34_input_layer_ex, outputs=resnet34_block_output_ex)\n",
    "resnet34_ex.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 비블록화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_32(input_shape=(32,32,3)):\n",
    "\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    #-----------------------------conv1 output size 112*112----------------------------------\n",
    "    x = keras.layers.Conv2D(64,(7,7),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(x)\n",
    "    shortcut = x\n",
    "    # ----------------------------conv2_x output size 56*56-----------------------------------\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #----------------------------------conv3_x---------------------------------------------\n",
    "    shortcut = keras.layers.Conv2D(128,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-------------------------------------conv4_x--------------------\n",
    "    shortcut = keras.layers.Conv2D(256,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #------------------------------------conv5_x----------------------------------------\n",
    "    shortcut = keras.layers.Conv2D(512,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same',strides=(2,2))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    x = keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(2,activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs = input_layer, outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 16, 16, 64)   9472        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 16, 16, 64)   256         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 16, 16, 64)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 7, 7, 64)     36928       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 7, 7, 64)     256         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 7, 7, 64)     0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 7, 7, 64)     36928       activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 7, 7, 64)     256         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 7, 7, 64)     0           batch_normalization_310[0][0]    \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 64)     0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 7, 7, 64)     36928       activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 7, 7, 64)     256         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 64)     0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 7, 7, 64)     36928       activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 7, 7, 64)     256         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 7, 7, 64)     0           batch_normalization_312[0][0]    \n",
      "                                                                 add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 64)     0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 7, 7, 64)     36928       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 7, 7, 64)     256         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 64)     0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 7, 7, 64)     36928       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 7, 7, 64)     256         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 7, 7, 64)     0           batch_normalization_314[0][0]    \n",
      "                                                                 add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 64)     0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 4, 4, 128)    73856       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 4, 4, 128)    512         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 4, 4, 128)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 4, 4, 128)    147584      activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 4, 4, 128)    8320        activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 4, 4, 128)    512         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 4, 4, 128)    512         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 4, 4, 128)    0           batch_normalization_317[0][0]    \n",
      "                                                                 batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 4, 4, 128)    0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 4, 4, 128)    147584      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 4, 4, 128)    512         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 4, 4, 128)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 4, 4, 128)    147584      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 4, 4, 128)    512         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 4, 4, 128)    0           batch_normalization_319[0][0]    \n",
      "                                                                 add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 4, 4, 128)    0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 4, 4, 128)    147584      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 4, 4, 128)    512         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 4, 4, 128)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 4, 4, 128)    147584      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 4, 4, 128)    512         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 4, 4, 128)    0           batch_normalization_321[0][0]    \n",
      "                                                                 add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 4, 4, 128)    0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 4, 4, 128)    147584      activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 4, 4, 128)    512         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 4, 4, 128)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 4, 4, 128)    147584      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 4, 4, 128)    512         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 4, 4, 128)    0           batch_normalization_323[0][0]    \n",
      "                                                                 add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 4, 4, 128)    0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 2, 2, 256)    295168      activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 2, 2, 256)    1024        conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 2, 2, 256)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 2, 2, 256)    590080      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 2, 2, 256)    33024       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 2, 2, 256)    1024        conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 2, 2, 256)    1024        conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 2, 2, 256)    0           batch_normalization_326[0][0]    \n",
      "                                                                 batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 2, 2, 256)    0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 2, 2, 256)    590080      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 2, 2, 256)    1024        conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 2, 2, 256)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 2, 2, 256)    590080      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 2, 2, 256)    1024        conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 2, 2, 256)    0           batch_normalization_328[0][0]    \n",
      "                                                                 add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 2, 2, 256)    0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 2, 2, 256)    590080      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 2, 2, 256)    1024        conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 2, 2, 256)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 2, 2, 256)    590080      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 2, 2, 256)    1024        conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 2, 2, 256)    0           batch_normalization_330[0][0]    \n",
      "                                                                 add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 2, 2, 256)    0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 2, 2, 256)    590080      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 2, 2, 256)    1024        conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 2, 2, 256)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 2, 2, 256)    590080      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 2, 2, 256)    1024        conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 2, 2, 256)    0           batch_normalization_332[0][0]    \n",
      "                                                                 add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 2, 2, 256)    0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 2, 2, 256)    590080      activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 2, 2, 256)    1024        conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 2, 2, 256)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 2, 2, 256)    590080      activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 2, 2, 256)    1024        conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 2, 2, 256)    0           batch_normalization_334[0][0]    \n",
      "                                                                 add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 2, 2, 256)    0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 2, 2, 256)    590080      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 2, 2, 256)    1024        conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 2, 2, 256)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 2, 2, 256)    590080      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 2, 2, 256)    1024        conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 2, 2, 256)    0           batch_normalization_336[0][0]    \n",
      "                                                                 add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 2, 2, 256)    0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 1, 1, 512)    1180160     activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 1, 1, 512)    2048        conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 1, 1, 512)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 1, 1, 512)    2359808     activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 1, 1, 512)    131584      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 1, 1, 512)    2048        conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 1, 1, 512)    2048        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 1, 1, 512)    0           batch_normalization_339[0][0]    \n",
      "                                                                 batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 1, 1, 512)    0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 1, 1, 512)    2359808     activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 1, 1, 512)    2048        conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 1, 1, 512)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 1, 1, 512)    2359808     activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 1, 1, 512)    2048        conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 1, 1, 512)    0           batch_normalization_341[0][0]    \n",
      "                                                                 add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 1, 1, 512)    0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 1, 1, 512)    2359808     activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 1, 1, 512)    2048        conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 1, 1, 512)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 1, 1, 512)    2359808     activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 1, 1, 512)    2048        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 1, 1, 512)    0           batch_normalization_343[0][0]    \n",
      "                                                                 add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 1, 1, 512)    0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 512)          0           activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 512)          0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            1026        flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,311,234\n",
      "Trainable params: 21,294,210\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_32().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_50(input_shape = (32,32,3)):\n",
    "    input_layer = keras.layers.Input(shape = input_shape)\n",
    "    x = input_layer\n",
    "    #--------------------------------conv1------------------------------------------------\n",
    "    x = keras.layers.ZeroPadding2D((3,3))(x)\n",
    "    x = keras.layers.Conv2D(64,(7,7),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.ZeroPadding2D((1,1))(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(x)\n",
    "    #--------------------------------conv2_x---------------------------------------------\n",
    "    shortcut = x\n",
    "    shortcut = keras.layers.Conv2D(256,(1,1),padding='valid')(shortcut)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #--------------------------------conv3_x-----------------------------------\n",
    "    \n",
    "    shortcut = keras.layers.Conv2D(512,(1,1),strides=(2,2),padding='valid')(shortcut)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-----------------------------------conv4_x--------------------------------------\n",
    " \n",
    "    shortcut = keras.layers.Conv2D(1024,(1,1),strides=(2,2),padding='valid')(shortcut)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    #-----------------------------------conv5_x-------------------------------------------\n",
    "\n",
    "    shortcut = keras.layers.Conv2D(2048,(1,1),strides=(2,2),padding='valid')(shortcut)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Add()([x,shortcut])\n",
    "    shortcut = x\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #----------------------------------------\n",
    "    x = keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(2,activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs = input_layer, outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 18, 18, 64)   0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 256)    16640       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 256)    1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 64)     16448       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 256)    16640       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     16448       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 64)     36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 256)    16640       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 256)    1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 256)    0           batch_normalization_46[0][0]     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 128)    32896       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 128)    512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 128)    147584      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 128)    512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 512)    66048       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 512)    131584      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 4, 4, 512)    0           batch_normalization_50[0][0]     \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 512)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 128)    65664       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 128)    512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 128)    512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 512)    66048       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 4, 512)    2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 4, 4, 512)    0           batch_normalization_53[0][0]     \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 512)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 128)    65664       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 128)    512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 128)    147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 4, 128)    512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 512)    66048       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 4, 512)    2048        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 4, 4, 512)    0           batch_normalization_56[0][0]     \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 512)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 128)    65664       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 4, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 128)    147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 4, 4, 128)    512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 4, 4, 128)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 512)    66048       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 4, 4, 512)    2048        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 4, 4, 512)    0           batch_normalization_59[0][0]     \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 4, 4, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 2, 2, 256)    131328      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 2, 2, 256)    1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2, 2, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 2, 2, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 2, 2, 256)    1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 2, 2, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 2, 2, 1024)   263168      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 2, 2, 1024)   525312      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 2, 2, 1024)   4096        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 2, 2, 1024)   4096        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 2, 2, 1024)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 2, 2, 256)    262400      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2, 2, 256)    1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 2, 2, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 2, 2, 256)    590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2, 2, 256)    1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 2, 2, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 2, 2, 1024)   263168      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 2, 2, 1024)   4096        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_66[0][0]     \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 2, 2, 1024)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 2, 2, 256)    262400      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 2, 2, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 2, 2, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 2, 2, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 2, 2, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 2, 2, 1024)   263168      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 2, 2, 1024)   4096        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_69[0][0]     \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 2, 2, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 2, 2, 256)    262400      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 2, 2, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 2, 2, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 2, 2, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 1024)   263168      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2, 2, 1024)   4096        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_72[0][0]     \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 2, 2, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 256)    262400      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 2, 2, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 2, 2, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 2, 2, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 256)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 1024)   263168      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 1024)   4096        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_75[0][0]     \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2, 2, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 256)    262400      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 2, 2, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 256)    1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 1024)   263168      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 1024)   4096        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_78[0][0]     \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 512)    524800      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 512)    2048        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 1, 1, 512)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 512)    2359808     activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 512)    2048        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1, 1, 512)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 2048)   2099200     add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 2048)   8192        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 2048)   8192        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_82[0][0]     \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1, 1, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 512)    1049088     activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 512)    2048        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 512)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 512)    2359808     activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 512)    2048        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 512)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 2048)   8192        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_85[0][0]     \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 512)    1049088     activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 512)    2048        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 512)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 512)    2359808     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 512)    2048        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 512)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 2048)   8192        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_88[0][0]     \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            4098        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_50().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_32_plain(input_shape=(32,32,3)):\n",
    "\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    #-----------------------------conv1 output size 112*112----------------------------------\n",
    "    x = keras.layers.Conv2D(64,(7,7),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(x)\n",
    "    # ----------------------------conv2_x output size 56*56-----------------------------------\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #----------------------------------conv3_x---------------------------------------------\n",
    "    shortcut = keras.layers.Conv2D(128,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-------------------------------------conv4_x--------------------\n",
    "    shortcut = keras.layers.Conv2D(256,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #------------------------------------conv5_x----------------------------------------\n",
    "    shortcut = keras.layers.Conv2D(512,(1,1),padding='same',strides=(2,2))(x)\n",
    "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same',strides=(2,2))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    x = keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(2,activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs = input_layer, outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_50_plain(input_shape = (32,32,3)):\n",
    "    input_layer = keras.layers.Input(shape = input_shape)\n",
    "    x = input_layer\n",
    "    #--------------------------------conv1------------------------------------------------\n",
    "    x = keras.layers.ZeroPadding2D((3,3))(x)\n",
    "    x = keras.layers.Conv2D(64,(7,7),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.ZeroPadding2D((1,1))(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(x)\n",
    "    #--------------------------------conv2_x---------------------------------------------\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #--------------------------------conv3_x-----------------------------------\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #-----------------------------------conv4_x--------------------------------------\n",
    "\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(256,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(1024,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    #-----------------------------------conv5_x-------------------------------------------\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),strides=(2,2),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(512,(3,3),padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.Conv2D(2048,(1,1),padding='valid')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #----------------------------------------\n",
    "    x = keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(2,activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs = input_layer, outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 20\n",
    "\n",
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_valid = apply_normalize_on_dataset(ds_valid, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_177 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_182 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_184 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_183 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_186 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_196 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_200 (Conv2D)          (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 21,134,722\n",
      "Trainable params: 21,119,490\n",
      "Non-trainable params: 15,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plain32_model = resnet_32_plain(input_shape=(224,224,3))\n",
    "\n",
    "plain32_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 257s 418ms/step - loss: 0.7623 - accuracy: 0.4998 - val_loss: 1.5734 - val_accuracy: 0.4972\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.7230 - accuracy: 0.5140 - val_loss: 0.7283 - val_accuracy: 0.5320\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.7116 - accuracy: 0.5063 - val_loss: 2.1914 - val_accuracy: 0.4861\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.7042 - accuracy: 0.5147 - val_loss: 0.7513 - val_accuracy: 0.5089\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.7031 - accuracy: 0.5105 - val_loss: 1.4202 - val_accuracy: 0.5637\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.6943 - accuracy: 0.5326 - val_loss: 2.4779 - val_accuracy: 0.4924\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.6883 - accuracy: 0.5537 - val_loss: 0.9592 - val_accuracy: 0.5825\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.6680 - accuracy: 0.5929 - val_loss: 0.6596 - val_accuracy: 0.6067\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.6446 - accuracy: 0.6284 - val_loss: 0.6322 - val_accuracy: 0.6446\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.6154 - accuracy: 0.6608 - val_loss: 0.9619 - val_accuracy: 0.6232\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 200s 344ms/step - loss: 0.5910 - accuracy: 0.6840 - val_loss: 0.7908 - val_accuracy: 0.6476\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 200s 345ms/step - loss: 0.5443 - accuracy: 0.7134 - val_loss: 0.6697 - val_accuracy: 0.6287\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.5132 - accuracy: 0.7489 - val_loss: 0.7038 - val_accuracy: 0.6102\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.4787 - accuracy: 0.7686 - val_loss: 0.5717 - val_accuracy: 0.7180\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.4314 - accuracy: 0.8016 - val_loss: 0.5849 - val_accuracy: 0.7275\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.3867 - accuracy: 0.8233 - val_loss: 0.6979 - val_accuracy: 0.6678\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.3290 - accuracy: 0.8575 - val_loss: 0.6574 - val_accuracy: 0.7054\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.2686 - accuracy: 0.8876 - val_loss: 0.7248 - val_accuracy: 0.7255\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 199s 343ms/step - loss: 0.2138 - accuracy: 0.9106 - val_loss: 0.7225 - val_accuracy: 0.7065\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 199s 342ms/step - loss: 0.1747 - accuracy: 0.9304 - val_loss: 0.8752 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    plain32_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history_plain_32 = plain32_model.fit(\n",
    "        ds_train,\n",
    "        steps_per_epoch=int(ds_info_train.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "        validation_steps=int(ds_info_valid.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "        epochs=EPOCH,\n",
    "        validation_data=ds_valid,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 276s 450ms/step - loss: 0.6640 - accuracy: 0.6166 - val_loss: 0.9789 - val_accuracy: 0.5356\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.5871 - accuracy: 0.6886 - val_loss: 0.5479 - val_accuracy: 0.7162\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.5199 - accuracy: 0.7405 - val_loss: 0.6353 - val_accuracy: 0.6805\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.4755 - accuracy: 0.7700 - val_loss: 0.7603 - val_accuracy: 0.6396\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.4000 - accuracy: 0.8181 - val_loss: 0.6414 - val_accuracy: 0.7320\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.3242 - accuracy: 0.8606 - val_loss: 0.8497 - val_accuracy: 0.7009\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.2498 - accuracy: 0.8971 - val_loss: 0.5014 - val_accuracy: 0.8152\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.1503 - accuracy: 0.9394 - val_loss: 0.6353 - val_accuracy: 0.7920\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0947 - accuracy: 0.9646 - val_loss: 0.8638 - val_accuracy: 0.7693\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0604 - accuracy: 0.9780 - val_loss: 1.2278 - val_accuracy: 0.7539\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 1.0802 - val_accuracy: 0.7832\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 260s 448ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 1.1461 - val_accuracy: 0.7781\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 1.2834 - val_accuracy: 0.7448\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 262s 450ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.9459 - val_accuracy: 0.8149\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0152 - accuracy: 0.9941 - val_loss: 1.1426 - val_accuracy: 0.7897\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.0591 - val_accuracy: 0.8242\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 1.1761 - val_accuracy: 0.8117\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 1.1170 - val_accuracy: 0.8180\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 1.1424 - val_accuracy: 0.8332\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 261s 449ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 1.0763 - val_accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "resnet32_model = resnet_32(input_shape=(224,224,3))\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    resnet32_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history_resnet_32 = resnet32_model.fit(\n",
    "        ds_train,\n",
    "        steps_per_epoch=int(ds_info_train.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "        validation_steps=int(ds_info_valid.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "        epochs=EPOCH,\n",
    "        validation_data=ds_valid,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "581/581 [==============================] - 469s 778ms/step - loss: 0.6860 - accuracy: 0.5844 - val_loss: 0.6877 - val_accuracy: 0.5786\n",
      "Epoch 2/10\n",
      "581/581 [==============================] - 451s 776ms/step - loss: 0.6423 - accuracy: 0.6401 - val_loss: 0.9865 - val_accuracy: 0.5316\n",
      "Epoch 3/10\n",
      "581/581 [==============================] - 452s 778ms/step - loss: 0.6304 - accuracy: 0.6453 - val_loss: 0.9911 - val_accuracy: 0.5361\n",
      "Epoch 4/10\n",
      "581/581 [==============================] - 451s 777ms/step - loss: 0.6297 - accuracy: 0.6558 - val_loss: 0.8186 - val_accuracy: 0.5602\n",
      "Epoch 5/10\n",
      "581/581 [==============================] - 452s 777ms/step - loss: 0.6026 - accuracy: 0.6753 - val_loss: 0.7096 - val_accuracy: 0.5987\n",
      "Epoch 6/10\n",
      "581/581 [==============================] - 451s 776ms/step - loss: 0.5994 - accuracy: 0.6809 - val_loss: 0.6736 - val_accuracy: 0.6437\n",
      "Epoch 7/10\n",
      "581/581 [==============================] - 452s 778ms/step - loss: 0.5842 - accuracy: 0.6875 - val_loss: 0.7247 - val_accuracy: 0.6362\n",
      "Epoch 8/10\n",
      "581/581 [==============================] - 452s 778ms/step - loss: 0.5621 - accuracy: 0.7102 - val_loss: 1.4065 - val_accuracy: 0.5318\n",
      "Epoch 9/10\n",
      "581/581 [==============================] - 451s 776ms/step - loss: 0.5475 - accuracy: 0.7200 - val_loss: 0.6303 - val_accuracy: 0.6978\n",
      "Epoch 10/10\n",
      "581/581 [==============================] - 451s 776ms/step - loss: 0.5351 - accuracy: 0.7311 - val_loss: 0.6991 - val_accuracy: 0.6198\n"
     ]
    }
   ],
   "source": [
    "resnet50_model = resnet_50(input_shape=(224,224,3))\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    resnet50_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history_resnet_50 = resnet50_model.fit(\n",
    "        ds_train,\n",
    "        steps_per_epoch=int(ds_info_train.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "        validation_steps=int(ds_info_valid.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "        epochs=10,\n",
    "        validation_data=ds_valid,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "581/581 [==============================] - 398s 658ms/step - loss: 0.7100 - accuracy: 0.5224 - val_loss: 0.7399 - val_accuracy: 0.4892\n",
      "Epoch 2/10\n",
      "581/581 [==============================] - 382s 658ms/step - loss: 0.7076 - accuracy: 0.5297 - val_loss: 2.0807 - val_accuracy: 0.4835\n",
      "Epoch 3/10\n",
      "581/581 [==============================] - 383s 658ms/step - loss: 0.7029 - accuracy: 0.5339 - val_loss: 9.3294 - val_accuracy: 0.4834\n",
      "Epoch 4/10\n",
      "581/581 [==============================] - 382s 658ms/step - loss: 0.6967 - accuracy: 0.5520 - val_loss: 0.6950 - val_accuracy: 0.5494\n",
      "Epoch 5/10\n",
      "581/581 [==============================] - 382s 658ms/step - loss: 0.6924 - accuracy: 0.5616 - val_loss: 0.7015 - val_accuracy: 0.5411\n",
      "Epoch 6/10\n",
      "581/581 [==============================] - 382s 657ms/step - loss: 0.6944 - accuracy: 0.5547 - val_loss: 0.6959 - val_accuracy: 0.5281\n",
      "Epoch 7/10\n",
      "581/581 [==============================] - 382s 658ms/step - loss: 0.6941 - accuracy: 0.5493 - val_loss: 0.7568 - val_accuracy: 0.5252\n",
      "Epoch 8/10\n",
      "581/581 [==============================] - 382s 657ms/step - loss: 0.6927 - accuracy: 0.5549 - val_loss: 0.7161 - val_accuracy: 0.5396\n",
      "Epoch 9/10\n",
      "581/581 [==============================] - 383s 660ms/step - loss: 0.6824 - accuracy: 0.5797 - val_loss: 1.6612 - val_accuracy: 0.5089\n",
      "Epoch 10/10\n",
      "581/581 [==============================] - 382s 658ms/step - loss: 0.6767 - accuracy: 0.5924 - val_loss: 0.6740 - val_accuracy: 0.5976\n"
     ]
    }
   ],
   "source": [
    "plain50_model = resnet_50_plain(input_shape=(224,224,3))\n",
    "with tf.device('/GPU:0'):\n",
    "    plain50_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history_plain_50 = plain50_model.fit(\n",
    "        ds_train,\n",
    "        steps_per_epoch=int(ds_info_train.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "        validation_steps=int(ds_info_valid.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "        epochs=10,\n",
    "        validation_data=ds_valid,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Resnet vs Plain 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_resnet_50.history['val_accuracy'], 'r')\n",
    "plt.plot(history_plain_50.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_resnet_50.history['loss'], 'r')\n",
    "plt.plot(history_plain_50.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f22e4166e10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(history_resnet_32.history['loss'], 'r')\n",
    "plt.plot(history_plain_32.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_34', 'plain_34'], loc='upper left')\n",
    "plt.show()\n",
    "history_resnet_32\n",
    "history_plain_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_resnet_32.history['val_accuracy'], 'r')\n",
    "plt.plot(history_plain_32.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_34', 'plain_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 처음으로 논문 구현을 해봤는데 정말 밤을 새워가면서 구현을 했습니다..비블록화를 먼저 구현하고 어떻게 블록화를 할 수 있을지 고민을\n",
    "많이 한게 코딩 실력에 많은 도움이 되었던 것 같습니다. 블록화를 함으로써 좀 더 효율적으로 코드를 짜는것을 공부했던 것 같습니다.\n",
    "- 확실히 Residual(shortcut)이 Plain에 비해 성능향상에 많은 도움이 되었던 것 같습니다. 이 논문이 왜 다른논문에 Backbon이나 인용이 많이 되었는지 알게 되었던 논문인 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
