{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [ 0.03249854  0.02337385  0.01238173 -0.02831428]\n",
      "  [ 0.02190229 -0.04441956  0.00677045 -0.01459743]\n",
      "  [ 0.00348527  0.00337044 -0.04351844  0.01361432]]\n",
      "\n",
      " [[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [-0.04933453 -0.0114877  -0.04175674  0.03641499]\n",
      "  [ 0.02977978  0.01542927 -0.02136786  0.0130757 ]\n",
      "  [ 0.00348527  0.00337044 -0.04351844  0.01361432]]\n",
      "\n",
      " [[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.04059618 -0.00025867 -0.02408453  0.03820194]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [ 0.03249854  0.02337385  0.01238173 -0.02831428]\n",
      "  [ 0.04914378 -0.00262272 -0.00732697  0.01384922]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) + len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 8s 141ms/step - loss: 0.6928 - accuracy: 0.5157 - val_loss: 0.6915 - val_accuracy: 0.4984\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.6856 - accuracy: 0.6078 - val_loss: 0.6744 - val_accuracy: 0.6821\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.6418 - accuracy: 0.7720 - val_loss: 0.5093 - val_accuracy: 0.8106\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.4179 - accuracy: 0.8508 - val_loss: 0.3527 - val_accuracy: 0.8488\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.2522 - accuracy: 0.9074 - val_loss: 0.3224 - val_accuracy: 0.8636\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1796 - accuracy: 0.9368 - val_loss: 0.3184 - val_accuracy: 0.8702\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.1257 - accuracy: 0.9639 - val_loss: 0.3381 - val_accuracy: 0.8650\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0883 - accuracy: 0.9787 - val_loss: 0.3683 - val_accuracy: 0.8628\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0577 - accuracy: 0.9890 - val_loss: 0.4091 - val_accuracy: 0.8601\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0387 - accuracy: 0.9938 - val_loss: 0.4406 - val_accuracy: 0.8581\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.0270 - accuracy: 0.9966 - val_loss: 0.4833 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0175 - accuracy: 0.9983 - val_loss: 0.5173 - val_accuracy: 0.8572\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0102 - accuracy: 0.9996 - val_loss: 0.5509 - val_accuracy: 0.8557\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.5813 - val_accuracy: 0.8558\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.6102 - val_accuracy: 0.8552\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.6266 - val_accuracy: 0.8553\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.6503 - val_accuracy: 0.8546\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.6704 - val_accuracy: 0.8543\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8533\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.7029 - val_accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 3s - loss: 0.7621 - accuracy: 0.8400\n",
      "[0.7620788216590881, 0.839959979057312]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ mkdir -p ~/aiffel/sentiment_classification/data\n",
    "$ pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03736787,  0.06856862,  0.00929755, -0.06917746, -0.0099615 ,\n",
       "        0.02280396, -0.0510356 , -0.05081595, -0.02018523,  0.023536  ,\n",
       "        0.08061603,  0.04591672,  0.04206234, -0.02704814, -0.04891394,\n",
       "       -0.02701971], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gackt', 0.9157851934432983),\n",
       " ('somewhat', 0.8561585545539856),\n",
       " ('willis', 0.8533880114555359),\n",
       " ('splendid', 0.8510239124298096),\n",
       " ('november', 0.8394675254821777),\n",
       " ('disc', 0.8388115167617798),\n",
       " ('masterpiece', 0.8354001045227051),\n",
       " ('durbin', 0.832733690738678),\n",
       " ('callahan', 0.8326024413108826),\n",
       " ('implied', 0.8292805552482605)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 19s 547ms/step - loss: 0.6896 - accuracy: 0.5348 - val_loss: 0.6718 - val_accuracy: 0.6002\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 14s 468ms/step - loss: 0.6539 - accuracy: 0.6327 - val_loss: 0.6104 - val_accuracy: 0.7004\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 15s 503ms/step - loss: 0.5621 - accuracy: 0.7370 - val_loss: 0.4441 - val_accuracy: 0.8229\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 13s 439ms/step - loss: 0.3873 - accuracy: 0.8427 - val_loss: 0.3437 - val_accuracy: 0.8524\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 0.2672 - accuracy: 0.8970 - val_loss: 0.3135 - val_accuracy: 0.8655\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 383ms/step - loss: 0.2038 - accuracy: 0.9257 - val_loss: 0.2886 - val_accuracy: 0.8808\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 0.1503 - accuracy: 0.9505 - val_loss: 0.2931 - val_accuracy: 0.8837\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 0.1111 - accuracy: 0.9678 - val_loss: 0.2978 - val_accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 11s 383ms/step - loss: 0.0856 - accuracy: 0.9814 - val_loss: 0.3142 - val_accuracy: 0.8820\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 11s 385ms/step - loss: 0.0661 - accuracy: 0.9866 - val_loss: 0.3499 - val_accuracy: 0.8737\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 0.0430 - accuracy: 0.9931 - val_loss: 0.3496 - val_accuracy: 0.8805\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 14s 455ms/step - loss: 0.0299 - accuracy: 0.9979 - val_loss: 0.3729 - val_accuracy: 0.8795\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 14s 454ms/step - loss: 0.0212 - accuracy: 0.9979 - val_loss: 0.3912 - val_accuracy: 0.8786\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 14s 459ms/step - loss: 0.0172 - accuracy: 0.9987 - val_loss: 0.4101 - val_accuracy: 0.8781\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 14s 455ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 0.4318 - val_accuracy: 0.8765\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 14s 456ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.4510 - val_accuracy: 0.8756\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 14s 455ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.4710 - val_accuracy: 0.8735\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 14s 459ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.4797 - val_accuracy: 0.8752\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 14s 484ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.4957 - val_accuracy: 0.8744\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 14s 454ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.5572 - accuracy: 0.8615\n",
      "[0.5571964383125305, 0.8614799976348877]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')   \n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')     \n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
