{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [ 0.03249854  0.02337385  0.01238173 -0.02831428]\n",
      "  [ 0.02190229 -0.04441956  0.00677045 -0.01459743]\n",
      "  [ 0.00348527  0.00337044 -0.04351844  0.01361432]]\n",
      "\n",
      " [[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [-0.04933453 -0.0114877  -0.04175674  0.03641499]\n",
      "  [ 0.02977978  0.01542927 -0.02136786  0.0130757 ]\n",
      "  [ 0.00348527  0.00337044 -0.04351844  0.01361432]]\n",
      "\n",
      " [[ 0.0180053   0.02828756  0.02722882 -0.01862228]\n",
      "  [-0.04059618 -0.00025867 -0.02408453  0.03820194]\n",
      "  [-0.00687931  0.02728362  0.03553797 -0.01649494]\n",
      "  [ 0.03249854  0.02337385  0.01238173 -0.02831428]\n",
      "  [ 0.04914378 -0.00262272 -0.00732697  0.01384922]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) + len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 9s 152ms/step - loss: 0.6931 - accuracy: 0.4980 - val_loss: 0.6918 - val_accuracy: 0.5075\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6864 - accuracy: 0.6183 - val_loss: 0.6754 - val_accuracy: 0.7159\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.6464 - accuracy: 0.7579 - val_loss: 0.5252 - val_accuracy: 0.8197\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.4417 - accuracy: 0.8566 - val_loss: 0.3389 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.2491 - accuracy: 0.9084 - val_loss: 0.3162 - val_accuracy: 0.8686\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1649 - accuracy: 0.9458 - val_loss: 0.3301 - val_accuracy: 0.8629\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1190 - accuracy: 0.9666 - val_loss: 0.3517 - val_accuracy: 0.8666\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.0811 - accuracy: 0.9828 - val_loss: 0.3800 - val_accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0572 - accuracy: 0.9899 - val_loss: 0.4180 - val_accuracy: 0.8588\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.0375 - accuracy: 0.9950 - val_loss: 0.4574 - val_accuracy: 0.8579\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.0315 - accuracy: 0.9956 - val_loss: 0.4909 - val_accuracy: 0.8569\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.0194 - accuracy: 0.9977 - val_loss: 0.5259 - val_accuracy: 0.8545\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.0144 - accuracy: 0.9987 - val_loss: 0.5573 - val_accuracy: 0.8559\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.5865 - val_accuracy: 0.8553\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.6142 - val_accuracy: 0.8533\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.6394 - val_accuracy: 0.8519\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 52ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.6674 - val_accuracy: 0.8533\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8529\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 55ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.7069 - val_accuracy: 0.8522\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 4s - loss: 0.7852 - accuracy: 0.8389\n",
      "[0.7852199077606201, 0.838919997215271]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ mkdir -p ~/aiffel/sentiment_classification/data\n",
    "$ pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02290684, -0.03573163,  0.03889965,  0.05928445, -0.04624502,\n",
       "        0.00685611,  0.03303703,  0.03737348, -0.04877507, -0.04782736,\n",
       "        0.01737613,  0.00730932, -0.03089509, -0.02569617,  0.01462876,\n",
       "       -0.07898005], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('travelling', 0.9353527426719666),\n",
       " ('odyssey', 0.8957688808441162),\n",
       " ('jimmy', 0.895456850528717),\n",
       " ('painting', 0.8928192853927612),\n",
       " ('deliciously', 0.8875299096107483),\n",
       " ('ultimatum', 0.8818394541740417),\n",
       " ('pleasantly', 0.8740700483322144),\n",
       " ('earl', 0.8729377388954163),\n",
       " ('sweet', 0.8724004626274109),\n",
       " ('rates', 0.8700487017631531)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 20s 531ms/step - loss: 0.7003 - accuracy: 0.5311 - val_loss: 0.6608 - val_accuracy: 0.6117\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 11s 380ms/step - loss: 0.6327 - accuracy: 0.6597 - val_loss: 0.5757 - val_accuracy: 0.7128\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 12s 391ms/step - loss: 0.5011 - accuracy: 0.7859 - val_loss: 0.4569 - val_accuracy: 0.7790\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 0.3531 - accuracy: 0.8536 - val_loss: 0.3512 - val_accuracy: 0.8484\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 12s 394ms/step - loss: 0.2428 - accuracy: 0.9109 - val_loss: 0.3181 - val_accuracy: 0.8649\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 12s 391ms/step - loss: 0.1643 - accuracy: 0.9505 - val_loss: 0.3144 - val_accuracy: 0.8647\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 12s 403ms/step - loss: 0.1132 - accuracy: 0.9739 - val_loss: 0.3118 - val_accuracy: 0.8667\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 12s 411ms/step - loss: 0.0776 - accuracy: 0.9873 - val_loss: 0.3389 - val_accuracy: 0.8634\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 12s 389ms/step - loss: 0.0539 - accuracy: 0.9948 - val_loss: 0.3279 - val_accuracy: 0.8667\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 0.0352 - accuracy: 0.9981 - val_loss: 0.3302 - val_accuracy: 0.8696\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 12s 393ms/step - loss: 0.0222 - accuracy: 0.9994 - val_loss: 0.3391 - val_accuracy: 0.8689\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0169 - accuracy: 0.9994 - val_loss: 0.3532 - val_accuracy: 0.8677\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 12s 386ms/step - loss: 0.0129 - accuracy: 0.9993 - val_loss: 0.3612 - val_accuracy: 0.8682\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 0.0097 - accuracy: 0.9997 - val_loss: 0.3674 - val_accuracy: 0.8703\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 12s 393ms/step - loss: 0.0072 - accuracy: 0.9998 - val_loss: 0.3750 - val_accuracy: 0.8702\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 12s 397ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.3835 - val_accuracy: 0.8713\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.3894 - val_accuracy: 0.8698\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 12s 394ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.3955 - val_accuracy: 0.8701\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 13s 423ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.4040 - val_accuracy: 0.8726\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.4080 - val_accuracy: 0.8713\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.4514 - accuracy: 0.8617\n",
      "[0.4514438807964325, 0.8617200255393982]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
